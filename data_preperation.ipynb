{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "import librosa\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files copied and CSV created successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_path = r\"C:\\Users\\serge\\OneDrive\\Desktop\\shorter_data\"\n",
    "output_folder = r\"C:\\Users\\serge\\OneDrive\\Desktop\\shorter_data\\data\"\n",
    "output_csv_file = \"cobined_csv.csv\"\n",
    "\n",
    "output_csv_path = os.path.join(output_folder, output_csv_file)\n",
    "with open(output_csv_path, \"w\", newline=\"\") as file:\n",
    "    csv_writer = csv.writer(file)\n",
    "    csv_writer.writerow([\"Index\", \"Sentence\"]) \n",
    "    \n",
    "    index = 1\n",
    "    \n",
    "    for folder_name in os.listdir(data_path):\n",
    "        folder_path = os.path.join(data_path, folder_name)\n",
    "        if os.path.isdir(folder_path) and folder_name.startswith(\"UX\"):\n",
    "            csv_file = os.path.join(folder_path, f\"{folder_name}.csv\")\n",
    "            if os.path.isfile(csv_file):\n",
    "                with open(csv_file, \"r\") as file:\n",
    "                    csv_reader = csv.reader(file, delimiter=\"|\")\n",
    "                    next(csv_reader)  \n",
    "                    \n",
    "                    for row in csv_reader:\n",
    "                        if len(row) >= 2:\n",
    "                            wav_file_name = row[0].strip() + \".wav\"\n",
    "                            sentence = row[1].strip()\n",
    "                            input_wav_file = os.path.join(folder_path, wav_file_name)\n",
    "                            \n",
    "                            if not os.path.isfile(input_wav_file):\n",
    "                                continue  \n",
    "                            \n",
    "                            output_wav_file = os.path.join(output_folder, f\"{index}.wav\")\n",
    "                            os.replace(input_wav_file, output_wav_file)\n",
    "                            \n",
    "                            csv_writer.writerow([index, sentence])\n",
    "                            \n",
    "                            index += 1\n",
    "                            \n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_dir = r\"C:\\Hackthon\\real_time_speeh_recongnition_mongolian_data\\preprocessed_data\"\n",
    "labels_file = r\"C:\\Hackthon\\real_time_speeh_recongnition_mongolian_data\\lower.csv\"\n",
    "\n",
    "manifest_entries = []\n",
    "\n",
    "labels_df = pd.read_csv(labels_file)\n",
    "\n",
    "for index, row in labels_df.iterrows():\n",
    "    audio_file = f\"{row['Index']}.wav\"\n",
    "    label = row['sentence']\n",
    "    \n",
    "    audio_path = os.path.join(audio_dir, audio_file)\n",
    "    \n",
    "    if not os.path.isfile(audio_path):\n",
    "        continue \n",
    "    try:\n",
    "        audio, sr = librosa.load(audio_path, sr=None)\n",
    "        \n",
    "        duration = len(audio) / sr\n",
    "        \n",
    "        manifest_entry = {\n",
    "            \"audio_filepath\": f\"/content/drive/MyDrive/real_time_speeh_recongnition_mongolian_data/preprocessed_data/{audio_file}\",\n",
    "            \"text\": label.lower(),\n",
    "            \"duration\": duration\n",
    "        }\n",
    "        \n",
    "        manifest_entries.append(manifest_entry)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing audio file {audio_file}: {str(e)}\")\n",
    "        continue  \n",
    "\n",
    "with open(\"manifest.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for entry in manifest_entries:\n",
    "        json_entry = json.dumps(entry, ensure_ascii=False)\n",
    "        f.write(json_entry + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "train_ratio = 0.84\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.01\n",
    "\n",
    "random.shuffle(manifest_entries)\n",
    "\n",
    "num_samples = len(manifest_entries)\n",
    "num_train = int(train_ratio * num_samples)\n",
    "num_validation = int(validation_ratio * num_samples)\n",
    "num_test = int(test_ratio * num_samples)\n",
    "\n",
    "train_entries = manifest_entries[:num_train]\n",
    "validation_entries = manifest_entries[num_train:num_train + num_validation]\n",
    "test_entries = manifest_entries[num_train + num_validation:num_train + num_validation + num_test]\n",
    "\n",
    "train_file = \"manifest_train.json\"\n",
    "validation_file = \"manifest_validation.json\"\n",
    "test_file = \"manifest_test.json\"\n",
    "\n",
    "with open(train_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for entry in train_entries:\n",
    "        json_entry = json.dumps(entry, ensure_ascii=False)\n",
    "        f.write(json_entry + \"\\n\")\n",
    "\n",
    "with open(validation_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for entry in validation_entries:\n",
    "        json_entry = json.dumps(entry, ensure_ascii=False)\n",
    "        f.write(json_entry + \"\\n\")\n",
    "\n",
    "with open(test_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for entry in test_entries:\n",
    "        json_entry = json.dumps(entry, ensure_ascii=False)\n",
    "        f.write(json_entry + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters: 103\n",
      "{'э', '-', 'm', 'u', 'z', 'ы', ',', 'п', 'i', 'g', 'ф', 'н', 'а', '1', 'я', 'б', 'a', '9', 'и', '№', 'в', 'г', 'з', '7', \"'\", 'c', 'f', '/', '$', '3', 'ц', 'j', ' ', '(', 'ү', 'ъ', 'д', 'ч', 'o', '?', '_', 'r', 'л', '’', '\\t', 'к', '0', ')', 'ь', 'y', 'q', 'ю', 'т', 'p', 'ш', '‘', ';', '“', 'ж', '%', 'х', '\\\\', 'с', 'ё', '8', 'w', 'b', '\\n', 'м', 'k', '5', 's', '”', 'о', ':', 'v', '!', '…', 'h', 'l', 'e', '2', '.', 'ѳ', 'n', '|', 'у', 'd', 'р', '&', 'е', 'ө', '–', '̆', 'й', '+', 't', 'x', '#', '\"', '»', '4', '6'}\n"
     ]
    }
   ],
   "source": [
    "with open(r'C:\\Hackthon\\real_time_speeh_recongnition_mongolian_data\\lower.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    next(reader)\n",
    "\n",
    "    unique_characters = set()\n",
    "\n",
    "    for row in reader:\n",
    "        value = row[1]\n",
    "\n",
    "        unique_characters.update(set(value))\n",
    "\n",
    "    character_count = len(unique_characters)\n",
    "\n",
    "print(\"Total Characters:\", character_count)\n",
    "print(unique_characters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LPR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
